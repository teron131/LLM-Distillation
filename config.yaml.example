llm:
  provider: "api-endpoint"

api-endpoint:
  api_base: "https://openrouter.ai/api/v1"
  api_key: "HARDCODED_API_KEY"
  model: "google/gemini-2.5-flash-lite"
  max_retries: 3                       # Number of retries for API calls
  retry_delay: 1.0                     # Initial delay between retries (seconds)
  sleep_time: 0.5                      # Small delay in seconds between batches to avoid rate limits

# Ingest configuration
ingest:
  default_format: "txt"  # Default output format for parsed files
  youtube_captions: "auto"  # Options: "auto", "manual" - caption preference

# LLM generation parameters
generation:
  temperature: 0.1   # Higher = more creative, lower = more deterministic
  top_p: 0.95        # Nucleus sampling parameter
  chunk_size: 4000   # Size of text chunks for processing
  overlap: 200       # Overlap between chunks to maintain context
  max_tokens: 4096   # Maximum tokens in LLM responses
  num_pairs: 50      # Default number of QA pairs to generate
  num_cot_examples: 5  # Default number of Chain of Thought examples to generate
  num_cot_enhance_examples: null  # Maximum number of conversations to enhance (null = enhance all)
  batch_size: 32     # Number of requests to batch together (for create)
  max_context_length: 8000       # Context Length of the MODEL. Useful while Generating Summary
  summary_overlap: 0       # Overlap between chunks to maintain context. Useful while Generating Summary
  
# Content curation parameters
curate:
  threshold: 7.0     # Default quality threshold (1-10)
  batch_size: 32      # Number of items per batch for rating (smaller batches for API stability)
  inference_batch: 32 # Number of batches to process at once with VLLM
  temperature: 0.1   # Temperature for rating (lower = more consistent)

# Format conversion parameters
format:
  default: "jsonl"   # Default output format
  include_metadata: true  # Include metadata in output files
  pretty_json: true  # Use indentation in JSON output

# Prompts for different tasks
prompts:
  # Summary generation prompt
  summary: |
    Summarize this document in 3-5 sentences, focusing on the main topic and key concepts.

  # QA pair generation prompt
  qa_generation: |
    Your task is to create high-quality question-answer pairs from the following text for the purpose of fine-tuning a Large Language Model.

    Adhere to the following rules:
    1. Base questions on the most important and factual information in the text.
    2. Ensure answers are directly and fully supported by the content of the text.
    3. Your response MUST be ONLY a valid JSON array of objects. Do not include any text, explanation, or markdown outside of the JSON array.

    Return the data in this exact JSON format:
    [
      {
        "question": "A clear and specific question about the text.",
        "answer": "A concise and accurate answer from the text."
      },
      {
        "question": "Another clear and specific question.",
        "answer": "Another concise and accurate answer."
      }
    ]

    Text to process:
    {text}

  # QA pair rating prompt
  qa_rating: |
    Your task is to rate the quality of the following question-answer pairs on a scale of 1 to 10.
    For each pair, consider these criteria:
    - Accuracy (0-3): Is the answer factually correct based solely on the provided text?
    - Relevance (0-2): Is the question and answer relevant to the main topics in the provided text?
    - Clarity (0-2): Is the language clear, concise, and easy to understand for both question and answer?
    - Usefulness (0-3): How valuable is this pair for fine-tuning an LLM? Does it teach useful information or reasoning?

    You MUST return ONLY a valid JSON array of objects, one for each QA pair, with this EXACT schema:
    [
      {
        "question": "The exact question text here.",
        "answer": "The exact answer text here.",
        "rating": <integer rating from 1 to 10>
      }
      // Add more objects in this array if there are multiple QA pairs.
      // Example for multiple pairs: [{"question": "Q1", "answer": "A1", "rating": 8}, {"question": "Q2", "answer": "A2", "rating": 9}]
    ]

    DO NOT include any introductory or concluding remarks, explanations, markdown formatting (like code blocks, bullet points, etc. outside the JSON itself), or any text that is not part of the valid JSON array.
    Your response must be ONLY the JSON array.

    Here are the QA pairs to rate:
    {pairs}

  # Chain of Thought generation prompt
  cot_generation: |
    Your task is to create complex reasoning examples from the provided text that demonstrate step-by-step, chain-of-thought thinking.

    Each example must contain:
    1. A challenging question that cannot be answered with a simple fact lookup and requires multi-step reasoning.
    2. A detailed "reasoning" section that breaks down the problem, explains the steps taken to arrive at the answer, and references the source text.
    3. A final, concise "answer".

    You MUST return ONLY a valid JSON array of objects. Do not include any text, explanation, or markdown outside of the JSON array.

    Return the data in this exact JSON format:
    [
      {
        "question": "A complex question that requires reasoning.",
        "reasoning": "Step 1: Analyze the first part of the problem...\nStep 2: Connect this to the second piece of information...\nStep 3: Conclude the final answer based on the previous steps.",
        "answer": "The final, concise answer."
      }
    ]

    Text to process:
    {text}

  # Chain of Thought enhancement prompt
  cot_enhancement: |
    You are an expert reasoning assistant. Your task is to enhance the user-assistant conversations provided below by adding a detailed, step-by-step "chain-of-thought" to the assistant's responses.

    Rules:
    1. Preserve the original answer in the assistant's response.
    2. Add the chain-of-thought reasoning *before* the original answer.
    3. The reasoning should explain how the assistant arrived at its answer.
    4. {include_simple_steps} Determines if reasoning should be added to simple responses.
    5. Your entire output MUST BE a valid JSON array of conversations, matching the original structure. Do not add any extra text or markdown.

    Return the enhanced conversations in this exact JSON format:
    [
      [
        {"role": "system", "content": "System message text."},
        {"role": "user", "content": "User's question."},
        {"role": "assistant", "content": "Let me think through this step by step:\\n\\n1. First, I need to analyze the user's request...\\n2. Then, I will formulate the steps to find the answer...\\n\\nTherefore, [original answer from the input]"}
      ]
    ]

    Original conversations to enhance:
    {conversations}
